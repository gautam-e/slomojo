{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Matmul -> Linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us put in the code fom the previous notebook, to do the imports an to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PythonInterface import Python\n",
    "\n",
    "let pathlib = Python.import_module(\"pathlib\") # Python standard library\n",
    "let gzip = Python.import_module(\"gzip\") # Python standard library\n",
    "let pickle = Python.import_module(\"pickle\") # Python standard library\n",
    "let np = Python.import_module(\"numpy\")\n",
    "\n",
    "# Get the data\n",
    "path_gz = pathlib.Path('./lost+found/data/mnist.pkl.gz')\n",
    "f = gzip.open(path_gz, 'rb')\n",
    "u = pickle._Unpickler(f)\n",
    "u.encoding = 'latin1'\n",
    "data = u.load()\n",
    "\n",
    "data_train = data[0]\n",
    "data_valid = data[1]\n",
    "\n",
    "x_train = data_train[0]\n",
    "y_train = data_train[1]\n",
    "y_train = np.expand_dims(y_train, 1)\n",
    "\n",
    "x_valid = data_valid[0]\n",
    "y_valid = data_valid[1]\n",
    "y_valid = np.expand_dims(y_valid, 1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DType import DType\n",
    "from Memory import memset_zero\n",
    "from Object import object, Attr\n",
    "from Pointer import DTypePointer, Pointer\n",
    "from Random import rand\n",
    "from Range import range\n",
    "from TargetInfo import dtype_sizeof\n",
    "\n",
    "struct Matrix[type: DType]:\n",
    "    var data: DTypePointer[type]\n",
    "    var rows: Int\n",
    "    var cols: Int\n",
    "\n",
    "    fn __init__(inout self, rows: Int, cols: Int):\n",
    "        self.data = DTypePointer[type].alloc(rows * cols)\n",
    "        rand(self.data, rows*cols)\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    fn __copyinit__(inout self, other: Self):\n",
    "        self.data = other.data\n",
    "        self.rows = other.rows\n",
    "        self.cols = other.cols\n",
    "\n",
    "    fn __del__(owned self):\n",
    "        self.data.free()\n",
    "\n",
    "    fn zero(inout self):\n",
    "        memset_zero(self.data, self.rows * self.cols)\n",
    "\n",
    "    @always_inline\n",
    "    fn __getitem__(self, y: Int, x: Int) -> SIMD[type, 1]:\n",
    "        return self.load[1](y, x)\n",
    "\n",
    "    @always_inline\n",
    "    fn load[nelts:Int](self, y: Int, x: Int) -> SIMD[type, nelts]:\n",
    "        return self.data.simd_load[nelts](y * self.cols + x)\n",
    "\n",
    "    @always_inline\n",
    "    fn __setitem__(self, y: Int, x: Int, val: SIMD[type, 1]):\n",
    "        return self.store[1](y, x, val)\n",
    "\n",
    "    @always_inline\n",
    "    fn store[nelts:Int](self, y: Int, x: Int, val: SIMD[type, nelts]):\n",
    "        self.data.simd_store[nelts](y * self.cols + x, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn matrix_dataloader[type: DType]( a:PythonObject, o: Matrix[type], bs: Int) raises:\n",
    "    for i in range(bs):\n",
    "        for j in range(o.cols):\n",
    "            o[i,j] = a[i][j].to_float64().cast[type]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let bs: Int = 5 # batch-size\n",
    "let ni: Int = x_train.shape[1].to_index() #28*28\n",
    "\n",
    "let xb: Matrix[DType.float32] = Matrix[DType.float32](bs,ni)\n",
    "let yb: Matrix[DType.float32] = Matrix[DType.float32](bs,1)\n",
    "xb.zero()\n",
    "yb.zero()\n",
    "\n",
    "matrix_dataloader(x_train, xb, bs)\n",
    "matrix_dataloader(y_train, yb, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear layer from foundations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear layer is nothing but a matrix multiplication (weights and activations) followed by a vector addition (with the bias term).  \n",
    "So the basic idea here is to use the the `matmul` example functions from the [Modular website](https://docs.modular.com/mojo/notebooks/Matmul.html) as a starting point and add the bias term in it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let no: Int = 10\n",
    "var w: Matrix[DType.float32] = Matrix[DType.float32](ni, no) # weights\n",
    "var b: Matrix[DType.float32] = Matrix[DType.float32](no, 1) # bias\n",
    "b.zero()\n",
    "var res = Matrix[DType.float32](xb.rows, w.cols) # result \n",
    "res.zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TargetInfo import dtype_sizeof, dtype_simd_width\n",
    "from Functional import vectorize\n",
    "\n",
    "alias nelts = dtype_simd_width[DType.float32]() # The SIMD vector width.\n",
    "\n",
    "fn lin_vectorized[type: DType](xb: Matrix[type], w: Matrix[type], b: Matrix[type], res: Matrix[type]) raises:\n",
    "    for i in range(xb.rows): # 50000\n",
    "        for j in range(xb.cols): # 784\n",
    "            @parameter\n",
    "            fn dotbias[nelts: Int](k: Int):\n",
    "                res.store[nelts](i,k, res.load[nelts](i,k) + xb[i,j] * w.load[nelts](j,k) + b.load[nelts](k,0))\n",
    "            vectorize[nelts, dotbias](w.cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.zero()\n",
    "lin_vectorized(xb, w, b, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(res.rows)\n",
    "print(res.cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
