{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "skip_showdoc: true\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”¥ Forward and backward pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us put in the code fom the previous notebook, to do the imports an to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from PythonInterface import Python\n",
        "\n",
        "let pathlib = Python.import_module(\"pathlib\") # Python standard library\n",
        "let gzip = Python.import_module(\"gzip\") # Python standard library\n",
        "let pickle = Python.import_module(\"pickle\") # Python standard library\n",
        "let np = Python.import_module(\"numpy\")\n",
        "\n",
        "# Get the data\n",
        "path_gz = pathlib.Path('./lost+found/data/mnist.pkl.gz')\n",
        "f = gzip.open(path_gz, 'rb')\n",
        "u = pickle._Unpickler(f)\n",
        "u.encoding = 'latin1'\n",
        "data = u.load()\n",
        "\n",
        "data_train = data[0]\n",
        "data_valid = data[1]\n",
        "\n",
        "x_train = data_train[0]\n",
        "y_train = data_train[1]\n",
        "y_train = np.expand_dims(y_train, 1)\n",
        "\n",
        "x_valid = data_valid[0]\n",
        "y_valid = data_valid[1]\n",
        "y_valid = np.expand_dims(y_valid, 1)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from DType import DType\n",
        "from Memory import memset_zero\n",
        "from Object import object, Attr\n",
        "from Pointer import DTypePointer, Pointer\n",
        "from Random import rand\n",
        "from Range import range\n",
        "from TargetInfo import dtype_sizeof\n",
        "\n",
        "struct Matrix[type: DType]:\n",
        "    var data: DTypePointer[type]\n",
        "    var rows: Int\n",
        "    var cols: Int\n",
        "\n",
        "    fn __init__(inout self, rows: Int, cols: Int):\n",
        "        self.data = DTypePointer[type].alloc(rows * cols)\n",
        "        rand(self.data, rows*cols)\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "\n",
        "    fn __copyinit__(inout self, other: Self):\n",
        "        self.data = other.data\n",
        "        self.rows = other.rows\n",
        "        self.cols = other.cols\n",
        "\n",
        "    fn __del__(owned self):\n",
        "        self.data.free()\n",
        "\n",
        "    fn zero(inout self):\n",
        "        memset_zero(self.data, self.rows * self.cols)\n",
        "\n",
        "    @always_inline\n",
        "    fn __getitem__(self, y: Int, x: Int) -> SIMD[type, 1]:\n",
        "        return self.load[1](y, x)\n",
        "\n",
        "    @always_inline\n",
        "    fn load[nelts:Int](self, y: Int, x: Int) -> SIMD[type, nelts]:\n",
        "        return self.data.simd_load[nelts](y * self.cols + x)\n",
        "\n",
        "    @always_inline\n",
        "    fn __setitem__(self, y: Int, x: Int, val: SIMD[type, 1]):\n",
        "        return self.store[1](y, x, val)\n",
        "\n",
        "    @always_inline\n",
        "    fn store[nelts:Int](self, y: Int, x: Int, val: SIMD[type, nelts]):\n",
        "        self.data.simd_store[nelts](y * self.cols + x, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "fn matrix_dataloader[type: DType]( a:PythonObject, o: Matrix[type], bs: Int) raises -> Matrix[type]:\n",
        "    for i in range(bs):\n",
        "        for j in range(o.cols):\n",
        "            o[i,j] = a[i][j].to_float64().cast[type]()\n",
        "    return o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "let bs: Int = 5 # batch-size\n",
        "let ni: Int = 28*28\n",
        "\n",
        "let xb: Matrix[DType.float32] = Matrix[DType.float32](bs,ni)\n",
        "let yb: Matrix[DType.float32] = Matrix[DType.float32](bs,1)\n",
        "xb.zero()\n",
        "yb.zero()\n",
        "\n",
        "xb = matrix_dataloader(x_train, xb, bs)\n",
        "yb = matrix_dataloader(y_train, yb, bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "let no: Int = 10\n",
        "var w: Matrix[DType.float32] = Matrix[DType.float32](ni, no) # weights\n",
        "var b: Matrix[DType.float32] = Matrix[DType.float32](no, 1) # bias\n",
        "b.zero()\n",
        "var res = Matrix[DType.float32](xb.rows, w.cols) # result \n",
        "res.zero()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from TargetInfo import dtype_sizeof, dtype_simd_width\n",
        "from Functional import vectorize\n",
        "\n",
        "alias nelts = dtype_simd_width[DType.float32]() # The SIMD vector width.\n",
        "\n",
        "fn lin_vectorized[type: DType](res: Matrix[type], xb: Matrix[type], w: Matrix[type], b: Matrix[type]) raises -> Matrix[type]:\n",
        "    for i in range(xb.rows): # 50000\n",
        "        for j in range(xb.cols): # 784\n",
        "            @parameter\n",
        "            fn dotbias[nelts: Int](k: Int):\n",
        "                res.store[nelts](i,k, res.load[nelts](i,k) + xb[i,j] * w.load[nelts](j,k) + b.load[nelts](k,0))\n",
        "            vectorize[nelts, dotbias](w.cols)\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "res.zero()\n",
        "res = lin_vectorized(res, xb, w, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "print(res.rows)\n",
        "print(res.cols)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Foundations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RELu from foundations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from Math import max\n",
        "\n",
        "fn relu_layer[type: DType](acts: Matrix[type], out: Matrix[type]) -> Matrix[type]:\n",
        "    @parameter\n",
        "    fn relu[nelts: Int](k: Int):\n",
        "        #let l = SIMD[type, nelts](0)\n",
        "        out.store[nelts](k,0, max[type, nelts](acts.load[nelts](k,0), 0.0))\n",
        "    vectorize[nelts, relu](acts.rows)\n",
        "    return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test that with an example. Firstly a little print function for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "fn print_matrix[type: DType](mat: Matrix[type]):\n",
        "    for row in range(mat.rows):\n",
        "        for col in range(mat.cols):\n",
        "            print(mat[row, col])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now, some dummy data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.76618862152099609\n",
            "0.21974173188209534\n",
            "0.11567939817905426\n",
            "-0.33300000429153442\n"
          ]
        }
      ],
      "source": [
        "# These are like the activations\n",
        "var x = Matrix[DType.float32](4, 1) \n",
        "x[3,0] = -0.333 # Intentionally have a negative value here\n",
        "print_matrix[DType.float32](x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "var res = Matrix[DType.float32](x.rows, x.cols) # Matrix to hold the result \n",
        "res.zero()\n",
        "print_matrix[DType.float32](res)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, the result has been initialized / zeroed out nicely. Let's see what it shows after claling the RELu function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.76618862152099609\n",
            "0.21974173188209534\n",
            "0.11567939817905426\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "var o = relu_layer[DType.float32](x, res)\n",
        "print_matrix(o)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks good. The negative values are being zeroed-out, while the positive values are the same as the input matrix.  \n",
        "Next up: The loss function."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss function from the foundations: MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from Math import pow\n",
        "\n",
        "fn loss[type: DType](y_pred: Matrix[type], y_true: Matrix[type], res: Matrix[type]):\n",
        "    @parameter\n",
        "    fn mse[nelts: Int](k: Int):\n",
        "        let sum_of_squares = pow[type, nelts](y_pred.load[nelts](k,0) - y_true.load[nelts](k,0), 2).reduce_add()\n",
        "        res.store[1](0, 0, res.load[1](0, 0) + sum_of_squares[0])\n",
        "    vectorize[nelts, mse](y_pred.rows)\n",
        "    res.store[1](0, 0, res.load[1](0, 0) / y_pred.rows )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us test that with a couple of examples.  \n",
        "First, if both inputs are zeros, then the loss should be zero.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "var y1 = Matrix[DType.float32](8, 1) \n",
        "y1.zero()\n",
        "var y2 = Matrix[DType.float32](8, 1) \n",
        "y2.zero()\n",
        "var l = Matrix[DType.float32](1, 1) \n",
        "l.zero()\n",
        "print(l[0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "loss[DType.float32](y1, y2, l)\n",
        "print(l[0,0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That looks fine.  \n",
        "Now if we have two random matrices, we would expect the loss to be non-zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "var y1 = Matrix[DType.float32](8, 1) \n",
        "var y2 = Matrix[DType.float32](8, 1) \n",
        "var l = Matrix[DType.float32](1, 1) \n",
        "l.zero()\n",
        "print(l[0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.21140147745609283\n"
          ]
        }
      ],
      "source": [
        "loss[DType.float32](y1, y2, l)\n",
        "print(l[0,0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And if both the vectors are equal, we should get zero loss again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "l.zero()\n",
        "loss[DType.float32](y1, y1, l)\n",
        "print(l[0,0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gradients and backward pass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
